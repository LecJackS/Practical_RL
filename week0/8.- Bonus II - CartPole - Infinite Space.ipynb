{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus II (4 points):\n",
    "* There are environments with continuous state spaces. In fact, most real world environments have this property. While we will dive into methods designed for that later, right now you already can solve them through binarization.\n",
    " * Gym has a basic infinite-state-space env called [CartPole](https://gym.openai.com/envs/CartPole-v0) - please start from this one. Solving something more challenging is great, but make sure your algorithm beats cartpole first. Also kudos for submitting.\n",
    " * Main idea: if you have something infinite and you want something discrete, you split it into bins. Like what histogram does.\n",
    " * Good choice of discretes is critical!\n",
    " * If the dimensionality is too high, you can try to reduce it (PCA/autoencoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "**Similar code as before:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-13 00:42:20,808] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "#from gym import wrappers\n",
    "\n",
    "#create a single game instance\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "#env = wrappers.Monitor(env, '/tmp/frozenlake8x8-v0')\n",
    "\n",
    "#start new game\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_states = 30\n",
    "n_space_high = env.observation_space.high\n",
    "n_space_low = env.observation_space.low\n",
    "# we should discretize this space\n",
    "discrete_states = np.linspace(n_space_low, n_space_high, n_states)\n",
    "n_actions = env.action_space.n\n",
    "def get_random_policy(pool=[]):\n",
    "    \"\"\"\n",
    "    Build a numpy array representing agent policy.\n",
    "    This array must have one element per each of 16 environment states.\n",
    "    Element must be an integer from 0 to 3, representing action\n",
    "    to take from that state.\n",
    "    \"\"\"\n",
    "    # randint(0, 4, 16) returns an array of integers between 0 and 3 inclusive\n",
    "    # (or, in other words, starting from 0 to below 4)\n",
    "    # and the third therm (16), will be the array size\n",
    "    rand_pol = np.random.randint(0, n_actions, n_states)\n",
    "    while rand_pol in pool:\n",
    "        #it will loop until a NEW random policy appear\n",
    "        print(\"rand_pol:\", rand_pol)\n",
    "        print(\"pool: \", pool)\n",
    "        rand_pol = np.random.randint(0, n_actions, n_states)\n",
    "        \n",
    "    return rand_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action frequencies over 10^4 samples: [ 0.49989  0.50011]\n",
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "policies = [get_random_policy() for i in range(10**4)]\n",
    "assert all([len(p) == n_states for p in policies]), 'policy length should always be 16'\n",
    "assert np.min(policies) == 0, 'minimal action id should be 0'\n",
    "assert np.max(policies) == n_actions-1, 'maximal action id should match n_actions-1'\n",
    "action_probas = np.unique(policies, return_counts=True)[-1] /10**4. /n_states\n",
    "print(\"Action frequencies over 10^4 samples:\",action_probas)\n",
    "assert np.allclose(action_probas, [1. / n_actions] * n_actions, atol=0.05), \"The policies aren't uniformly random (maybe it's just an extremely bad luck)\"\n",
    "print(\"Seems fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evaluate!\n",
    "* Implement a simple function that runs one game and returns the total reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_reward(env, policy, t_max=20000):\n",
    "    \"\"\"\n",
    "    Interact with an environment, return sum of all rewards.\n",
    "    If game doesn't end on t_max (e.g. agent walks into a wall), \n",
    "    force end the game and return whatever reward you got so far.\n",
    "    Tip: see signature of env.step(...) method above.\n",
    "    \"\"\"\n",
    "    #s: state; where our actor is\n",
    "    s = env.reset()\n",
    "    (pos, cart_v, pole_angle, pole_v) = s\n",
    "    total_reward = 0\n",
    "    t = 0\n",
    "    is_done = False\n",
    "    \n",
    "    while t < t_max and not is_done:\n",
    "        # p = policy: with probabilities equal to the ones returned by get_random_policy()\n",
    "        s, reward, is_done, _ = env.step(policy[s])\n",
    "        (pos, cart_v, pole_angle, pole_v) = s\n",
    "        print(\"s: \",s)\n",
    "        # accumulating rewards\n",
    "        total_reward += reward\n",
    "        t+=1\n",
    "    #s = env.reset()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating 10^3 sessions...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dbb6e457c0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generating 10^3 sessions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_random_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_reward must return a single number'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#assert all([0 <= r <= 1 for r in rewards]), 'total rewards should be between 0 and 1 for frozenlake (if solving taxi, delete this line)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dbb6e457c0de>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generating 10^3 sessions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_random_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_reward must return a single number'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#assert all([0 <= r <= 1 for r in rewards]), 'total rewards should be between 0 and 1 for frozenlake (if solving taxi, delete this line)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-99cc791e66cd>\u001b[0m in \u001b[0;36msample_reward\u001b[0;34m(env, policy, t_max)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt_max\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# p = policy: with probabilities equal to the ones returned by get_random_policy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# accumulating rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "print(\"generating 10^3 sessions...\")\n",
    "rewards = [sample_reward(env,get_random_policy()) for _ in range(10**3)]\n",
    "assert all([type(r) in (int, float) for r in rewards]), 'sample_reward must return a single number'\n",
    "#assert all([0 <= r <= 1 for r in rewards]), 'total rewards should be between 0 and 1 for frozenlake (if solving taxi, delete this line)'\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(policy, n_times=10):\n",
    "    \"\"\"Run several evaluations and average the score the policy gets.\"\"\"\n",
    "    # rewards: array with n_times (100) elements consisting of the total_rewards returned by sample_reward()\n",
    "    rewards = [sample_reward(env, policy) for n in range(n_times)]\n",
    "    #print(\"rewards: \", rewards)\n",
    "    return float(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring the random search, jumping right into\n",
    "# Part II - Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random policy:\n",
      "< : d | d : v : p\n",
      "p : < : p : d : p\n",
      "v : p : d : p : p\n",
      "< | < : > | < : ^\n",
      "< | ^ : d | < : p\n"
     ]
    }
   ],
   "source": [
    "def print_policy(policy):\n",
    "    pass\n",
    "\n",
    "print(\"random policy:\")\n",
    "print_policy(get_random_policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossover(policy1, policy2, p=0.5):\n",
    "    \"\"\"\n",
    "    for each state, with probability p take action from policy1, else policy2\n",
    "    \"\"\"\n",
    "    # policyx: [0,1,3,2,1,0,3,2,1,0,3,2,0,2,2,1]\n",
    "    new_pol = []\n",
    "    for i in range(len(policy1)):\n",
    "        #choosing between the ith element between pol1 and pol2 with probability p\n",
    "        new_pol.append(np.random.choice((policy1[i], policy2[i]), p=[p, 1-p]))\n",
    "        \n",
    "    return new_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutation(policy, p=0.01):\n",
    "    \"\"\"\n",
    "    for each state, with probability p replace action with random action\n",
    "    Tip: mutation can be written as crossover with random policy\n",
    "    \"\"\"\n",
    "    # if we modify \"policy\" directly, we'll change the value of policy. Lists work that way, so we\n",
    "    # need to use a copy\n",
    "    mutated_policy = list(policy)\n",
    "    #n_actions = env.action_space.n\n",
    "    for a in policy:\n",
    "        # with 1% probability, we mutate element a from policy\n",
    "        if np.random.choice((0,1), p=[1-p, p]):\n",
    "            mutated_policy[a] = np.random.randint(0, n_actions)\n",
    "    return mutated_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "policies = [crossover(get_random_policy(), get_random_policy()) \n",
    "            for i in range(10**2)]\n",
    "\n",
    "assert all([len(p) == n_states for p in policies]), 'policy length should always be 16'\n",
    "assert np.min(policies) == 0, 'minimal action id should be 0'\n",
    "assert np.max(policies) == n_actions-1, 'maximal action id should be n_actions-1'\n",
    "\n",
    "assert any([np.mean(crossover(np.zeros(n_states), np.ones(n_states))) not in (0, 1)\n",
    "               for _ in range(100)]), \"Make sure your crossover changes each action independently\"\n",
    "print(\"Seems fine!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000 #default: 100 - how many cycles to make\n",
    "pool_size = 100 #how many policies to maintain\n",
    "n_crossovers = 100 #how many crossovers to make on each step\n",
    "n_mutations = 200 #how many mutations to make on each tick\n",
    "n_low_scorers = 0 #how many random low-scorer policies, not into the best scorers, can pass to the next pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing...\n"
     ]
    }
   ],
   "source": [
    "print(\"initializing...\")\n",
    "#pool = <spawn a list of pool_size random policies>\n",
    "pool = [get_random_policy() for i in range(pool_size)]\n",
    "#pool_scores = <evaluate every policy in the pool, return list of scores>\n",
    "pool_scores = [evaluate(p) for p in pool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert type(pool) == type(pool_scores) == list\n",
    "assert len(pool) == len(pool_scores) == pool_size\n",
    "assert all([type(score) in (float, int) for score in pool_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diverse Pool\n",
    "\n",
    "### As with 4.-moar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/1000 [00:24<6:53:36, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "^ : p | d : > : >\n",
      "> : v : v : v : p\n",
      "d : v : > : p : p\n",
      "d | p : d | < : v\n",
      "p | d : v | < : ^\n",
      "\n",
      "Epoch 1:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:49<6:52:41, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -380.0\n",
      "^ : ^ | v : < : d\n",
      "> : v : < : d : ^\n",
      "d : > : d : d : >\n",
      "< | p : < | < : <\n",
      "^ | < : v | d : v\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [01:13<6:49:47, 24.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -379.1\n",
      "< : > | < : v : <\n",
      "> : p : d : v : v\n",
      "d : v : p : p : <\n",
      "d | v : d | < : >\n",
      "^ | d : p | < : ^\n",
      "\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [01:38<6:47:01, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -378.2\n",
      "> : > | ^ : < : >\n",
      "^ : > : d : v : v\n",
      "^ : p : < : p : ^\n",
      "> | < : d | p : >\n",
      "^ | p : p | d : v\n",
      "\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [02:02<6:44:09, 24.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -378.2\n",
      "d : < | p : v : d\n",
      "> : > : > : p : v\n",
      "p : p : v : v : <\n",
      "^ | v : > | > : v\n",
      "> | ^ : p | < : <\n",
      "\n",
      "Epoch 5:\n",
      "We found 2 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [02:26<6:42:15, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -379.1\n",
      "p : ^ | > : > : ^\n",
      "v : < : ^ : p : p\n",
      "< : p : > : v : <\n",
      "v | v : < | > : v\n",
      "> | ^ : < | d : p\n",
      "\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [02:49<6:38:45, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -378.2\n",
      "v : p | < : v : d\n",
      "d : ^ : d : p : ^\n",
      "^ : p : < : > : v\n",
      "p | < : p | ^ : p\n",
      "d | p : > | ^ : v\n",
      "\n",
      "Epoch 7:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1000 [03:13<6:37:17, 24.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : < | v : v : d\n",
      "< : > : > : ^ : ^\n",
      "^ : v : > : < : ^\n",
      "> | p : v | ^ : >\n",
      "d | > : v | > : d\n",
      "\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [03:37<6:35:58, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -378.2\n",
      "d : < | d : v : d\n",
      "d : ^ : d : p : ^\n",
      "^ : p : < : > : v\n",
      "p | < : p | ^ : p\n",
      "d | p : > | ^ : v\n",
      "\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [04:01<6:34:00, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "d : d | ^ : ^ : <\n",
      "v : v : ^ : ^ : <\n",
      "^ : p : ^ : ^ : >\n",
      "v | < : d | ^ : v\n",
      "d | > : ^ | < : <\n",
      "\n",
      "Epoch 10:\n",
      "We found 2 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 11/1000 [04:25<6:33:49, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : d | < : p : d\n",
      "^ : < : > : p : ^\n",
      "> : p : < : p : v\n",
      "> | < : p | d : >\n",
      "d | p : < | v : ^\n",
      "\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1000 [04:49<6:34:42, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -379.1\n",
      "d : < | p : < : d\n",
      "^ : > : d : ^ : ^\n",
      "p : p : > : > : ^\n",
      "> | p : p | < : >\n",
      "d | > : < | > : v\n",
      "\n",
      "Epoch 12:\n",
      "We found 2 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 13/1000 [05:13<6:33:48, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : v | ^ : v : <\n",
      "^ : > : d : p : ^\n",
      "d : v : d : p : ^\n",
      "< | < : v | d : >\n",
      "d | p : p | d : v\n",
      "\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 14/1000 [05:37<6:33:02, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : p | d : < : <\n",
      "> : < : d : ^ : ^\n",
      "> : p : < : p : ^\n",
      "^ | v : v | d : >\n",
      "^ | p : p | ^ : ^\n",
      "\n",
      "Epoch 14:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 15/1000 [06:00<6:31:08, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -376.4\n",
      "^ : < | d : v : >\n",
      "v : > : > : > : v\n",
      "^ : p : < : v : ^\n",
      "< | < : v | < : >\n",
      "^ | > : p | d : d\n",
      "\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 16/1000 [06:24<6:28:33, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : p | < : < : ^\n",
      "< : > : > : > : v\n",
      "^ : v : > : p : v\n",
      "^ | p : > | d : <\n",
      "d | < : < | < : d\n",
      "\n",
      "Epoch 16:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 17/1000 [06:47<6:27:49, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : ^ | < : < : ^\n",
      "< : < : > : > : v\n",
      "^ : v : > : v : p\n",
      "> | v : > | d : <\n",
      "d | < : < | < : d\n",
      "\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 18/1000 [07:11<6:26:42, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : v | < : v : >\n",
      "v : > : > : > : v\n",
      "^ : p : < : v : ^\n",
      "< | < : v | < : >\n",
      "^ | > : p | d : d\n",
      "\n",
      "Epoch 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 19/1000 [07:34<6:25:08, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : ^ | d : v : d\n",
      "^ : > : d : p : ^\n",
      "p : p : < : > : ^\n",
      "> | < : d | ^ : >\n",
      "d | p : p | d : v\n",
      "\n",
      "Epoch 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 20/1000 [07:58<6:24:45, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "^ : > | > : ^ : <\n",
      "> : > : d : p : v\n",
      "d : v : d : < : ^\n",
      "< | < : v | < : >\n",
      "^ | p : p | d : d\n",
      "\n",
      "Epoch 20:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 21/1000 [08:21<6:24:31, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "^ : < | v : v : >\n",
      "v : > : > : > : v\n",
      "^ : p : < : v : ^\n",
      "< | < : v | < : >\n",
      "^ | > : p | d : d\n",
      "\n",
      "Epoch 21:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 22/1000 [08:46<6:29:10, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -377.3\n",
      "< : d | > : < : ^\n",
      "< : > : > : > : v\n",
      "^ : v : > : < : v\n",
      "> | p : v | d : <\n",
      "d | < : < | v : d\n",
      "\n",
      "Epoch 22:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23/1000 [09:10<6:31:26, 24.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : v | v : v : <\n",
      "> : > : d : > : p\n",
      "d : v : d : v : ^\n",
      "< | < : v | d : >\n",
      "^ | > : p | d : d\n",
      "\n",
      "Epoch 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 24/1000 [09:35<6:33:01, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : p | p : < : >\n",
      "> : > : > : > : v\n",
      "^ : p : ^ : < : ^\n",
      "> | < : v | d : <\n",
      "^ | p : p | v : d\n",
      "\n",
      "Epoch 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 25/1000 [09:59<6:33:34, 24.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : p | < : < : ^\n",
      "< : > : > : > : v\n",
      "^ : v : > : p : v\n",
      "^ | p : > | d : <\n",
      "d | < : < | < : d\n",
      "\n",
      "Epoch 25:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 26/1000 [10:23<6:33:51, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : > | d : < : >\n",
      "> : > : d : > : p\n",
      "d : p : > : < : v\n",
      "> | < : v | d : >\n",
      "^ | p : < | d : d\n",
      "\n",
      "Epoch 26:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 27/1000 [10:48<6:33:15, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : ^ | v : v : ^\n",
      "^ : > : > : > : p\n",
      "> : p : > : v : ^\n",
      "< | < : > | < : <\n",
      "d | < : < | > : d\n",
      "\n",
      "Epoch 27:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 28/1000 [11:12<6:33:28, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : ^ | d : < : >\n",
      "< : > : > : > : v\n",
      "^ : p : d : < : ^\n",
      "> | < : v | < : <\n",
      "^ | < : p | v : v\n",
      "\n",
      "Epoch 28:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 29/1000 [11:36<6:33:11, 24.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : p | d : < : >\n",
      "> : > : > : > : v\n",
      "^ : v : > : < : v\n",
      "> | < : v | d : <\n",
      "^ | < : < | v : d\n",
      "\n",
      "Epoch 29:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 30/1000 [12:00<6:30:10, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "d : ^ | ^ : < : ^\n",
      "> : > : > : > : v\n",
      "d : p : > : v : v\n",
      "> | p : v | d : <\n",
      "d | p : < | d : d\n",
      "\n",
      "Epoch 30:\n",
      "We found 2 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 31/1000 [12:24<6:27:28, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : < | ^ : v : >\n",
      "^ : > : > : > : v\n",
      "> : p : < : < : ^\n",
      "< | < : v | < : <\n",
      "d | < : p | > : d\n",
      "\n",
      "Epoch 31:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 32/1000 [12:48<6:26:21, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : p | p : v : ^\n",
      "> : > : > : > : p\n",
      "^ : v : < : < : ^\n",
      "< | < : v | d : <\n",
      "^ | < : p | v : d\n",
      "\n",
      "Epoch 32:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 33/1000 [13:11<6:25:33, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : < | d : < : ^\n",
      "< : > : d : > : p\n",
      "^ : p : > : p : ^\n",
      "> | < : v | < : >\n",
      "^ | p : p | v : d\n",
      "\n",
      "Epoch 33:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 34/1000 [13:35<6:23:38, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : > | d : < : >\n",
      "> : > : d : ^ : v\n",
      "^ : v : > : < : v\n",
      "> | < : v | < : <\n",
      "^ | p : p | d : d\n",
      "\n",
      "Epoch 34:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 35/1000 [13:59<6:22:48, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "d : v | v : < : ^\n",
      "< : > : > : p : v\n",
      "^ : v : < : < : v\n",
      "> | < : v | d : >\n",
      "^ | < : p | v : d\n",
      "\n",
      "Epoch 35:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 36/1000 [14:23<6:23:32, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : d | ^ : < : >\n",
      "> : > : > : ^ : v\n",
      "^ : p : > : v : ^\n",
      "< | < : v | < : <\n",
      "^ | p : p | d : d\n",
      "\n",
      "Epoch 36:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 37/1000 [14:46<6:21:00, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : < | ^ : < : ^\n",
      "> : > : > : p : v\n",
      "^ : v : d : < : ^\n",
      "> | < : v | d : <\n",
      "^ | < : p | v : d\n",
      "\n",
      "Epoch 37:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 38/1000 [15:10<6:19:36, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : v | v : < : >\n",
      "^ : > : > : > : v\n",
      "^ : v : > : p : ^\n",
      "> | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 38:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 39/1000 [15:33<6:19:10, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : > | ^ : < : ^\n",
      "< : > : > : p : v\n",
      "^ : v : < : < : v\n",
      "> | < : v | d : <\n",
      "^ | < : p | v : d\n",
      "\n",
      "Epoch 39:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 40/1000 [15:57<6:18:42, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : d | d : < : ^\n",
      "^ : > : > : > : v\n",
      "^ : v : d : < : v\n",
      "> | < : v | d : <\n",
      "d | < : p | v : d\n",
      "\n",
      "Epoch 40:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 41/1000 [16:21<6:20:22, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : d | < : < : >\n",
      "< : > : > : p : p\n",
      "^ : v : > : < : v\n",
      "> | < : v | d : >\n",
      "^ | < : p | v : d\n",
      "\n",
      "Epoch 41:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 42/1000 [16:45<6:20:42, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : > | v : < : >\n",
      "^ : > : > : > : v\n",
      "^ : v : > : p : ^\n",
      "> | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 42:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 43/1000 [17:09<6:21:16, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : d | d : v : ^\n",
      "> : > : > : > : v\n",
      "^ : v : d : < : v\n",
      "> | < : v | d : <\n",
      "d | < : p | v : d\n",
      "\n",
      "Epoch 43:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 44/1000 [17:33<6:19:15, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : v | d : < : ^\n",
      "^ : > : > : > : v\n",
      "^ : p : > : < : ^\n",
      "> | < : v | ^ : <\n",
      "^ | p : p | d : d\n",
      "\n",
      "Epoch 44:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 45/1000 [17:57<6:19:17, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : p | p : < : >\n",
      "> : > : > : > : p\n",
      "^ : v : < : p : ^\n",
      "> | < : v | d : >\n",
      "^ | p : < | v : d\n",
      "\n",
      "Epoch 45:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 46/1000 [18:21<6:20:44, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "^ : v | p : < : >\n",
      "^ : > : > : > : v\n",
      "^ : p : > : p : v\n",
      "> | < : p | < : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 46:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 47/1000 [18:46<6:24:47, 24.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : d | < : < : >\n",
      "^ : > : > : > : v\n",
      "^ : v : > : p : ^\n",
      "> | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 47:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 48/1000 [19:11<6:26:55, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : > | ^ : < : ^\n",
      "> : > : > : > : v\n",
      "^ : v : < : < : v\n",
      "< | < : v | d : <\n",
      "^ | > : p | v : d\n",
      "\n",
      "Epoch 48:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 49/1000 [19:35<6:27:33, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : ^ | ^ : < : ^\n",
      "^ : > : > : > : v\n",
      "^ : v : < : < : ^\n",
      "> | < : v | d : >\n",
      "^ | p : < | v : d\n",
      "\n",
      "Epoch 49:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 50/1000 [19:59<6:25:19, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "d : ^ | v : < : >\n",
      "^ : > : > : p : v\n",
      "d : p : > : < : v\n",
      "< | < : v | < : >\n",
      "d | > : p | v : d\n",
      "\n",
      "Epoch 50:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 51/1000 [20:24<6:25:12, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : d | p : < : >\n",
      "> : > : > : p : v\n",
      "d : v : < : < : v\n",
      "> | < : v | ^ : <\n",
      "^ | < : < | v : d\n",
      "\n",
      "Epoch 51:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 52/1000 [20:48<6:23:27, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : > | > : < : >\n",
      "^ : > : > : > : v\n",
      "^ : v : > : < : v\n",
      "> | < : v | d : >\n",
      "d | > : < | v : d\n",
      "\n",
      "Epoch 52:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 53/1000 [21:12<6:25:13, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : p | > : < : >\n",
      "^ : > : > : > : v\n",
      "^ : v : < : < : v\n",
      "> | < : v | d : >\n",
      "d | > : p | v : d\n",
      "\n",
      "Epoch 53:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 54/1000 [21:37<6:26:17, 24.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : > | < : v : >\n",
      "^ : > : > : p : v\n",
      "^ : p : > : p : v\n",
      "< | < : v | d : >\n",
      "d | < : < | v : d\n",
      "\n",
      "Epoch 54:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 55/1000 [22:01<6:24:49, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : > | > : < : >\n",
      "> : > : > : > : p\n",
      "^ : v : > : p : ^\n",
      "> | < : v | d : >\n",
      "d | > : < | v : d\n",
      "\n",
      "Epoch 55:\n",
      "We found 2 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 56/1000 [22:26<6:23:25, 24.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "< : ^ | ^ : < : >\n",
      "^ : > : > : > : p\n",
      "^ : v : > : < : v\n",
      "> | < : v | d : >\n",
      "d | > : p | v : d\n",
      "\n",
      "Epoch 56:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 57/1000 [22:51<6:26:59, 24.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "p : > | > : < : >\n",
      "> : > : > : > : v\n",
      "^ : v : < : p : v\n",
      "> | < : v | d : >\n",
      "^ | > : p | v : d\n",
      "\n",
      "Epoch 57:\n",
      "We found 1 duplicated policies at this epoch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 58/1000 [23:15<6:25:56, 24.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "d : p | p : < : >\n",
      "> : > : > : > : p\n",
      "^ : v : < : p : v\n",
      "> | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 58:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 59/1000 [23:39<6:22:47, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "> : > | < : v : >\n",
      "> : > : > : > : v\n",
      "d : p : < : p : ^\n",
      "> | < : p | d : <\n",
      "^ | p : < | d : d\n",
      "\n",
      "Epoch 59:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 60/1000 [24:03<6:18:43, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : > | p : < : >\n",
      "> : > : > : > : v\n",
      "^ : v : < : p : v\n",
      "< | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 60:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 61/1000 [24:27<6:16:43, 24.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -200.0\n",
      "v : ^ | v : < : >\n",
      "^ : > : > : > : p\n",
      "^ : v : > : < : ^\n",
      "> | < : v | d : >\n",
      "^ | > : < | v : d\n",
      "\n",
      "Epoch 61:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-f0a495c26dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcrossovered\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#pool_scores = <evaluate all policies again>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mpool_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# 2. Adding a couple of random low scorers to the final pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-f0a495c26dac>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcrossovered\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#pool_scores = <evaluate all policies again>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mpool_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# 2. Adding a couple of random low scorers to the final pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-e97906d652e6>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(policy, n_times)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Run several evaluations and average the score the policy gets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# rewards: array with n_times (100) elements consisting of the total_rewards returned by sample_reward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\"rewards: \", rewards)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-e97906d652e6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Run several evaluations and average the score the policy gets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# rewards: array with n_times (100) elements consisting of the total_rewards returned by sample_reward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msample_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(\"rewards: \", rewards)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-1a1b9bd3c678>\u001b[0m in \u001b[0;36msample_reward\u001b[0;34m(env, policy, t_max)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt_max\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# p = policy: with probabilities equal to the ones returned by get_random_policy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# accumulating rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacks/anaconda3/lib/python3.5/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacks/anaconda3/lib/python3.5/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacks/anaconda3/lib/python3.5/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacks/anaconda3/lib/python3.5/site-packages/gym/envs/toy_text/discrete.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtransitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtransitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacks/anaconda3/lib/python3.5/site-packages/gym/envs/toy_text/discrete.py\u001b[0m in \u001b[0;36mcategorical_sample\u001b[0;34m(prob_n, np_random)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprob_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcsprob_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcsprob_n\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#main loop\n",
    "from tqdm import tqdm\n",
    "#for epoch in range(n_epochs):\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    print(\"Epoch %s:\"%epoch)\n",
    "    \n",
    "    # 1. Removing duplicates from pool\n",
    "    # converting list of np arrays to list of tuples because I couldn't find a better way to remove duplicates\n",
    "    uniques_pool = [tuple(policy) for policy in pool]\n",
    "    # set() returns only unique elements. We need to convert them to np arrays again\n",
    "    uniques_pool = [np.asarray(policy) for policy in set(uniques_pool)]\n",
    "    if len(uniques_pool) != len(pool):\n",
    "        # We found some duplicates\n",
    "        print(\"We found\", len(pool) - len(uniques_pool), \"duplicated policies at this epoch!\")\n",
    "        pool = uniques_pool\n",
    "        # we should fill pool with new random policies to keep it size, but with the code below\n",
    "        # it will be maintain it's size.\n",
    "    # We could check for duplicates on crossovered or mutated,\n",
    "    #but it's more similar code and I want to finish this one\n",
    "    \n",
    "    # evaluation policies before crossovering them:\n",
    "    pool_scores = [evaluate(p) for p in pool]\n",
    "    # we'll select the best n_crossovers (50) policies to mix between them\n",
    "    # we could use another number of best policies instead of n_crossovers (50),\n",
    "    # but it's late and I don't know what I'm doing\n",
    "    selected_indices = np.argsort(pool_scores)[-n_crossovers:]\n",
    "    \n",
    "    #crossovered = <crossover random guys from pool, n_crossovers total>\n",
    "    # using selected_indices as a fraction of pool with 50 best scores\n",
    "    crossovered = [crossover(pool[np.random.choice(selected_indices)], \n",
    "                             pool[np.random.choice(len(pool))]) \n",
    "                   for c in range(n_crossovers)]\n",
    "    # from now on it's all the same: mutations, adding all to a pool, evaluating (again) and selecting\n",
    "    # best scores. Repeat for n_epochs.\n",
    "    #mutated = <add several new policies at random, n_mutations total>\n",
    "    mutated = [mutation(pool[np.random.choice(len(pool))]) \n",
    "               for m in range(n_mutations)]\n",
    "    \n",
    "    assert type(crossovered) == type(mutated) == list\n",
    "    \n",
    "    #add new policies to the pool\n",
    "    #pool = <add up old population with crossovers/mutations>\n",
    "    #plus sing (+) concatenates lists in python\n",
    "    pool = pool + crossovered + mutated\n",
    "    #pool_scores = <evaluate all policies again>\n",
    "    pool_scores = [evaluate(p) for p in pool]\n",
    "    \n",
    "    # 2. Adding a couple of random low scorers to the final pool\n",
    "    # select pool_size-n_low_scorers best policies. we'll add n_low_scorers later \n",
    "    selected_indices = np.argsort(pool_scores)[-pool_size+n_low_scorers:]\n",
    "    # Now we need to add n_low_scorers to our indices\n",
    "    # np.argsort(pool_scores)[:-pool_size+n_low_scorers] will contain all indices NOT used abobe\n",
    "    # so we need to choose n_low_scorers random indices from there\n",
    "    low_scorers_indices = np.random.choice(np.argsort(pool_scores)[:-pool_size+n_low_scorers], n_low_scorers)\n",
    "    # now we need to concatenate all indices into one numpy array\n",
    "    selected_indices = np.concatenate((selected_indices, low_scorers_indices))\n",
    "    #filling pool only with best values\n",
    "    pool = [pool[i] for i in selected_indices]\n",
    "    pool_scores = [pool_scores[i] for i in selected_indices]\n",
    "\n",
    "    #print the best policy so far (last in ascending score order)\n",
    "    print(\"Best score:\", pool_scores[-1])\n",
    "    print_policy(pool[-1])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from gym import wrappers\n",
    "#env = gym.make('CartPole-v0')\n",
    "#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1')\n",
    "#for i_episode in range(20):\n",
    "#    observation = env.reset()\n",
    "#    for t in range(100):\n",
    "#        env.render()\n",
    "#        print(observation)\n",
    "#        action = env.action_space.sample()\n",
    "#        observation, reward, done, info = env.step(action)\n",
    "#        if done:\n",
    "#            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "#            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
